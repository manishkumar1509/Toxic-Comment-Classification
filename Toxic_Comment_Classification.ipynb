{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic Comment Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKi0vrF95Y5U",
        "colab_type": "text"
      },
      "source": [
        "Here I am using an ensemble method with the combination of **NB-SVM** baseline model and the LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TL8FXOu5YxX",
        "colab_type": "text"
      },
      "source": [
        "## NB-SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzGMORP45UpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd, numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import io\n",
        "import matplotlib as plt\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7t6YvCP-wbT",
        "colab_type": "text"
      },
      "source": [
        "Importing Files from local to Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5izFCbWr-lBP",
        "colab_type": "code",
        "outputId": "81984d70-4e02-4598-f51e-d9441c2a548b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-faf38b20-40c8-415e-b402-a4725d21b727\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-faf38b20-40c8-415e-b402-a4725d21b727\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sample_submission.csv to sample_submission.csv\n",
            "Saving test.csv to test.csv\n",
            "Saving test_labels.csv to test_labels.csv\n",
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBGgRtE57m0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv(io.BytesIO(uploaded['train.csv']))\n",
        "test=pd.read_csv(io.BytesIO(uploaded['test.csv']))\n",
        "subm=pd.read_csv(io.BytesIO(uploaded['sample_submission.csv']))\n",
        "test_labels=pd.read_csv('test_labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQjLpN6pNe9D",
        "colab_type": "text"
      },
      "source": [
        "#Looking at the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTUMyuonNlnX",
        "colab_type": "text"
      },
      "source": [
        "The training data contains a row per comment, with an id, the text of the comment, and 6 different labels that we'll try to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zplmJ2dANpRk",
        "colab_type": "code",
        "outputId": "2971d1f4-0c22-4ee5-aa3e-94c34b65764d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "5  00025465d4725e87  ...             0\n",
              "6  0002bcb3da6cb337  ...             0\n",
              "7  00031b1e95af7921  ...             0\n",
              "8  00037261f536c51d  ...             0\n",
              "9  00040093b2687caa  ...             0\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdsELsxqNykB",
        "colab_type": "code",
        "outputId": "587fd925-28cf-46ee-94a3-de9bb772eacc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text\n",
              "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
              "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
              "4  00017695ad8997eb          I don't anonymously edit articles at all."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRIwAEI4N3Rz",
        "colab_type": "text"
      },
      "source": [
        "The length of comment varies a lot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB8GhEvmN5Cy",
        "colab_type": "code",
        "outputId": "d3d9ba2b-ed3a-49fa-ee49-2138805d6b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lens = train.comment_text.str.len()\n",
        "lens.mean(), lens.std(), lens.max()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(394.0732213246768, 590.7202819048923, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1fbT4GnN8B6",
        "colab_type": "code",
        "outputId": "b0b89035-3725-4b0a-c6c7-43feb6a5e267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "lens.hist()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2dbf9d8160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il3SyqRNOEnL",
        "colab_type": "text"
      },
      "source": [
        "Most of the comments lie between 0-1000 size length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkrVYIdpOGdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG2LQkzPOKv9",
        "colab_type": "text"
      },
      "source": [
        "We'll create a list of all the labels to predict, and we'll also create a 'none' label so we can see how many comments have no labels. We can then summarize the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYeSSWq7OLSL",
        "colab_type": "code",
        "outputId": "c01d1f03-c6f7-4783-8bd1-7e79aa15a220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "train['none'] = 1-train[labels].max(axis=1)\n",
        "train.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>none</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>159571.000000</td>\n",
              "      <td>159571.000000</td>\n",
              "      <td>159571.000000</td>\n",
              "      <td>159571.000000</td>\n",
              "      <td>159571.000000</td>\n",
              "      <td>159571.000000</td>\n",
              "      <td>159571.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.095844</td>\n",
              "      <td>0.009996</td>\n",
              "      <td>0.052948</td>\n",
              "      <td>0.002996</td>\n",
              "      <td>0.049364</td>\n",
              "      <td>0.008805</td>\n",
              "      <td>0.898321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.294379</td>\n",
              "      <td>0.099477</td>\n",
              "      <td>0.223931</td>\n",
              "      <td>0.054650</td>\n",
              "      <td>0.216627</td>\n",
              "      <td>0.093420</td>\n",
              "      <td>0.302226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               toxic   severe_toxic  ...  identity_hate           none\n",
              "count  159571.000000  159571.000000  ...  159571.000000  159571.000000\n",
              "mean        0.095844       0.009996  ...       0.008805       0.898321\n",
              "std         0.294379       0.099477  ...       0.093420       0.302226\n",
              "min         0.000000       0.000000  ...       0.000000       0.000000\n",
              "25%         0.000000       0.000000  ...       0.000000       1.000000\n",
              "50%         0.000000       0.000000  ...       0.000000       1.000000\n",
              "75%         0.000000       0.000000  ...       0.000000       1.000000\n",
              "max         1.000000       1.000000  ...       1.000000       1.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2wKAB0JOQt9",
        "colab_type": "text"
      },
      "source": [
        "We see that the dataset looks balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPGa7yOOORNj",
        "colab_type": "code",
        "outputId": "92bace90-acd7-4386-a624-e32567186c29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train),len(test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159571, 153164)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSlYdOYOOU9s",
        "colab_type": "code",
        "outputId": "1f2431f9-72d6-4d17-91fe-ef53dbfce487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train.isnull().sum(axis=0)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               0\n",
              "comment_text     0\n",
              "toxic            0\n",
              "severe_toxic     0\n",
              "obscene          0\n",
              "threat           0\n",
              "insult           0\n",
              "identity_hate    0\n",
              "none             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1GlG0jFOZeT",
        "colab_type": "text"
      },
      "source": [
        "Since there are no NULL values we need not set values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRvRku28OcAR",
        "colab_type": "text"
      },
      "source": [
        "# Buliding the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo4uQ64AOiZ2",
        "colab_type": "text"
      },
      "source": [
        "We'll start by creating a bag of words representation, as a term document matrix. We'll use ngrams, as suggested in the NBSVM paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTLNhG9QOjDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re, string\n",
        "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
        "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oecIXoVQOonA",
        "colab_type": "text"
      },
      "source": [
        "We use TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0-afFvGOpDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = train.shape[0]\n",
        "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
        "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
        "               smooth_idf=1, sublinear_tf=1 )\n",
        "train_term_doc = vec.fit_transform(train['comment_text'])\n",
        "test_term_doc = vec.transform(test['comment_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SZ1eTJDOuol",
        "colab_type": "text"
      },
      "source": [
        "This creates a sparse matrix with only a small number of non-zero elements (stored elements in the representation below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MCOqrI9OvEp",
        "colab_type": "code",
        "outputId": "ecc4a513-9093-4d05-c418-3cca3b833f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_term_doc, test_term_doc"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<159571x426005 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 17775119 stored elements in Compressed Sparse Row format>,\n",
              " <153164x426005 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 14765768 stored elements in Compressed Sparse Row format>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qnYBWffOzH7",
        "colab_type": "text"
      },
      "source": [
        "Navie Bayes feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rbKHwBqO1j9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pr(y_i, y):\n",
        "    p = x[y==y_i].sum(0)\n",
        "    return (p+1) / ((y==y_i).sum()+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaYJvoLfO3Ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = train_term_doc\n",
        "test_x = test_term_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt1CnQ4gO7Ab",
        "colab_type": "text"
      },
      "source": [
        "Fit a model one dependent at a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV73jD6AO9AK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mdl(y):\n",
        "    y = y.values\n",
        "    r = np.log(pr(1,y) / pr(0,y))\n",
        "    m = LogisticRegression(C=4, dual=False)\n",
        "    x_nb = x.multiply(r)\n",
        "    return m.fit(x_nb, y), r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RJUUGglO_dU",
        "colab_type": "code",
        "outputId": "283fd1b3-a335-4a84-ad0a-a89e25414142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzgAootrPBaW",
        "colab_type": "code",
        "outputId": "1b2fe3d9-5742-46f2-95db-552f541c8e7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "preds = np.zeros((len(test), len(labels)))\n",
        "\n",
        "for i, j in enumerate(labels):\n",
        "    print('fit', j)\n",
        "    m,r = get_mdl(train[j])\n",
        "    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fit toxic\n",
            "fit severe_toxic\n",
            "fit obscene\n",
            "fit threat\n",
            "fit insult\n",
            "fit identity_hate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmCVN5nMPInF",
        "colab_type": "code",
        "outputId": "598c60d4-046f-497f-8739-412ac5c728f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "preds"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99987679e-01, 1.09154131e-01, 9.99987295e-01, 2.33988849e-03,\n",
              "        9.62474045e-01, 9.51723454e-02],\n",
              "       [2.82989151e-03, 5.87428825e-04, 1.86115135e-03, 8.87962734e-05,\n",
              "        2.21521436e-03, 3.30644095e-04],\n",
              "       [1.17593301e-02, 8.42350096e-04, 5.54908986e-03, 9.04142202e-05,\n",
              "        3.19115572e-03, 2.87817114e-04],\n",
              "       ...,\n",
              "       [1.37616560e-03, 1.54317536e-04, 2.65625841e-03, 7.03447088e-05,\n",
              "        9.37527477e-04, 1.86825842e-04],\n",
              "       [8.01977683e-03, 3.28158768e-04, 2.24673613e-03, 8.66010098e-05,\n",
              "        2.19951809e-03, 8.58965899e-04],\n",
              "       [9.45071422e-01, 1.13486460e-04, 4.24275383e-01, 3.19035022e-04,\n",
              "        4.44254625e-02, 7.94593208e-04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXp7MBpiWFpz",
        "colab_type": "text"
      },
      "source": [
        "Creating the submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V_LvQmZQWO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
        "submission = pd.concat([submid, pd.DataFrame(preds, columns = labels)], axis=1)\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhMBoowEe9q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jacy6acwe-EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59rtoQA1e-jm",
        "colab_type": "text"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQtguTgxfR36",
        "colab_type": "text"
      },
      "source": [
        "Here we attempt to tackle this classification problem by using Keras LSTM. \n",
        "We import the standard Keras library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMlJsNeOe9nw",
        "colab_type": "code",
        "outputId": "b29c8e6c-0401-47ea-ae69-4fdc0eb1dc62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lOvZKwcft2I",
        "colab_type": "text"
      },
      "source": [
        "Loading the train and test files, we have already loaded the file as train and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLNx6GeFf7uE",
        "colab_type": "text"
      },
      "source": [
        "Since we have already checked that there are no null values, so we need not deal with it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxLO3oe2gNXy",
        "colab_type": "text"
      },
      "source": [
        "the dependent variables are in the training set itself so we need to split them up, into X and Y sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuHHOnLffz7O",
        "colab_type": "code",
        "outputId": "77c6ffb2-6707-4070-8b0b-132c15ea1ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok8ukDabgUei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = train[labels].values\n",
        "list_sentences_train = train[\"comment_text\"]\n",
        "list_sentences_test = test[\"comment_text\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1OeJh2oguwR",
        "colab_type": "text"
      },
      "source": [
        "**The approach:** we need to feed the comments into the LSTM as part of the neural network but we can't just feed the words as it is.\n",
        "\n",
        "So this is what we are going to do:\n",
        "\n",
        "\n",
        "\n",
        "1.   **Tokenization** - We need to break down the sentence into unique words. For eg, \"I love cats and love dogs\" will become [\"I\",\"love\",\"cats\",\"and\",\"dogs\"]\n",
        "2.   **Indexing** - We put the words in a dictionary-like structure and give them an index each For eg, {1:\"I\",2:\"love\",3:\"cats\",4:\"and\",5:\"dogs\"}\n",
        "3. **Index Representation** - We could represent the sequence of words in the comments in the form of index, and feed this chain of index into our LSTM. For eg, [1,2,3,4,2,5]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyPm-2WNgu42",
        "colab_type": "text"
      },
      "source": [
        "In Keras, all the above steps can be done in 4 lines of code. Note that we have to define the number of unique words in our dictionary when tokenizing the sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as52G3eagXIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 20000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(list_sentences_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8NW7y-eiLx0",
        "colab_type": "text"
      },
      "source": [
        "To look up the occurences and index of each word in the dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeAEJjMphp1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#commented it due to long output\n",
        "#for occurence of words:\n",
        "#tokenizer.word_counts\n",
        "#for index of words:\n",
        "#tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "magDN-i0ig4q",
        "colab_type": "text"
      },
      "source": [
        "Now, if you look at \"list_tokenized_train\", you will see that Keras has turned our words into index representation for us"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgAhi1uVh-KY",
        "colab_type": "code",
        "outputId": "7c884710-39ff-43ef-9ce4-e2332a8af853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "list_tokenized_train[:1]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[688,\n",
              "  75,\n",
              "  1,\n",
              "  126,\n",
              "  130,\n",
              "  177,\n",
              "  29,\n",
              "  672,\n",
              "  4511,\n",
              "  12052,\n",
              "  1116,\n",
              "  86,\n",
              "  331,\n",
              "  51,\n",
              "  2278,\n",
              "  11448,\n",
              "  50,\n",
              "  6864,\n",
              "  15,\n",
              "  60,\n",
              "  2756,\n",
              "  148,\n",
              "  7,\n",
              "  2937,\n",
              "  34,\n",
              "  117,\n",
              "  1221,\n",
              "  15190,\n",
              "  2825,\n",
              "  4,\n",
              "  45,\n",
              "  59,\n",
              "  244,\n",
              "  1,\n",
              "  365,\n",
              "  31,\n",
              "  1,\n",
              "  38,\n",
              "  27,\n",
              "  143,\n",
              "  73,\n",
              "  3462,\n",
              "  89,\n",
              "  3085,\n",
              "  4583,\n",
              "  2273,\n",
              "  985]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMcFgb48jFuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enXQhmhzi7ea",
        "colab_type": "text"
      },
      "source": [
        "There's another problem! What if some comments are terribly long, while some are just 1 word? Wouldn't our indexed-sentence look like this:\n",
        "\n",
        "Comment #1: [8,9,3,7,3,6,3,6,3,6,2,3,4,9]\n",
        "\n",
        "Comment #2: [1,2]\n",
        "\n",
        "And we have to feed a stream of data that has a consistent length(fixed number of features) isn't it?\n",
        "\n",
        "And this is why we use \"padding\"! We could make the shorter sentences as long as the others by filling the shortfall by zeros.But on the other hand, we also have to trim the longer ones to the same length(maxlen) as the short ones. In this case, we have set the max length to be 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBm3prXLilVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 200\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMyg06dyjiww",
        "colab_type": "text"
      },
      "source": [
        "How do you know what is the best \"maxlen\" to set? If you put it too short, you might lose some useful feature that could cost you some accuracy points down the path.If you put it too long, your LSTM cell will have to be larger to store the possible values or states.\n",
        "\n",
        "One of the ways to go about it is to see the distribution of the number of words in sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjcJEm57jLBn",
        "colab_type": "code",
        "outputId": "0ff800bf-714c-433f-d4a4-f212f86bc1d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]\n",
        "plt.hist(totalNumWords,bins = np.arange(0,410,10))\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNpts0Fj2q-",
        "colab_type": "text"
      },
      "source": [
        "As we can see, most of the sentence length is about 30+. We could set the \"maxlen\" to about 50, but I'm being paranoid so I have set to 200. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOVC5NHtkCQm",
        "colab_type": "text"
      },
      "source": [
        "# Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c21obQUIkY4R",
        "colab_type": "text"
      },
      "source": [
        "This is the architecture of the model we are trying to build. It's always to good idea to list out the dimensions of each layer in the model to think visually and help you to debug later on.\n",
        "![alt text](https://i.imgur.com/txJomEa.png)\n",
        "\n",
        "As mentioned earlier, the inputs into our networks are our list of encoded sentences. We begin our defining an Input layer that accepts a list of sentences that has a dimension of 200. \n",
        "\n",
        "![alt text](https://i.imgur.com/uSjU4J7.png)\n",
        "\n",
        "By indicating an empty space after comma, we are telling Keras to infer the number automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTVYc-XPjpn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = Input(shape=(maxlen, )) #maxlen=200 as defined earlier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbwEfpKMlJ3M",
        "colab_type": "text"
      },
      "source": [
        "Next, we pass it to our Embedding layer, where we project the words to a defined vector space depending on the distance of the surrounding words in a sentence. Embedding allows us to reduce model size and most importantly the huge dimensions we have to deal with, in the case of using one-hot encoding to represent the words in our sentence.The output of the Embedding layer is just a list of the coordinates of the words in this vector space. For eg. (-81.012) for \"cat\" and (-80.012) for \"dog\". We could also use the distance of these coordinates to detect relevance and context. Embedding is a pretty deep topic, and if you are interested, this is a comprehensive guide: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n",
        "\n",
        "We need to define the size of the \"vector space\" we have mentioned above, and the number of unique words(max_features) we are using. Again, the embedding size is a parameter that you can tune and experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI-Qxu1jlElf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 128\n",
        "x = Embedding(max_features, embed_size)(inp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PrCZKS8mxP4",
        "colab_type": "text"
      },
      "source": [
        "Next, we feed this Tensor into the LSTM layer. We set the LSTM to produce an output that has a dimension of 60 and want it to return the whole unrolled sequence of results. As you probably know, LSTM or RNN works by recursively feeding the output of a previous network into the input of the current network, and you would take the final output after X number of recursion. But depending on use cases, you might want to take the unrolled, or the outputs of each recursion as the result to pass to the next layer. And this is the case.\n",
        "\n",
        "![alt text](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n",
        "\n",
        "From the above picture, the unrolled LSTM would give us a set of h0,h1,h2 until the last h.\n",
        "\n",
        "From the short line of code that defines the LSTM layer, it's easy to miss the required input dimensions. LSTM takes in a tensor of [Batch Size, Time Steps, Number of Inputs]. Batch size is the number of samples in a batch, time steps is the number of recursion it runs for each input, or it could be pictured as the number of \"A\"s in the above picture. Lastly, number of inputs is the number of variables(number of words in each sentence in our case) you pass into LSTM as pictured in \"x\" above.\n",
        "\n",
        "We can make use of the output from the previous embedding layer which outputs a 3-D tensor of (None, 200, 128) into the LSTM layer. What it does is going through the samples, recursively run the LSTM model for 200 times, passing in the coordinates of the words each time. And because we want the unrolled version, we will receive a Tensor shape of (None, 200, 60), where 60 is the output dimension we have defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d80b_1csmuh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = LSTM(60, return_sequences=True,name='lstm_layer')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntqoxGhLnC8-",
        "colab_type": "text"
      },
      "source": [
        "Before we could pass the output to a normal layer, we need to reshape the 3D tensor into a 2D one. We reshape carefully to avoid throwing away data that is important to us, and ideally we want the resulting data to be a good representative of the original data.\n",
        "\n",
        "Therefore, we use a Global Max Pooling layer which is traditionally used in CNN problems to reduce the dimensionality of image data. In simple terms, we go through each patch of data, and we take the maximum values of each patch. These collection of maximum values will be a new set of down-sized data we can use.\n",
        "\n",
        "As you can see from other Kaggle kernels, different variants (Average,Max,etc) of pooling layers are used for dimensionality reduction and they could yield different results so do try them out.\n",
        "\n",
        "If you are interested in finding out the technical details of pooling, read up here: https://wiseodd.github.io/techblog/2016/07/18/convnet-maxpool-layer/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zsht7qwnAz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = GlobalMaxPool1D()(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzMAPkO0nCQQ",
        "colab_type": "text"
      },
      "source": [
        "With a 2D Tensor in our hands, we pass it to a Dropout layer which indiscriminately \"disable\" some nodes so that the nodes in the next layer is forced to handle the representation of the missing data and the whole network could result in better generalization.\n",
        "\n",
        "![alt text](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_5/dropout.jpeg)\n",
        "\n",
        "We set the dropout layer to drop out 10%(0.1) of the nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlgATO-DnTwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Dropout(0.1)(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJrPn0KxnYM_",
        "colab_type": "text"
      },
      "source": [
        "After a drop out layer, we connect the output of drop out layer to a densely connected layer and the output passes through a RELU function. In short, this is what it does:\n",
        "\n",
        "Activation( (Input X Weights) + Bias)\n",
        "\n",
        "all in 1 line, with the weights, bias and activation layer all set up for you! We have defined the Dense layer to produce a output dimension of 50.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRZ6O_NbnVos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Dense(50, activation=\"relu\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4N4JqwenhGB",
        "colab_type": "text"
      },
      "source": [
        "We feed the output into a Dropout layer again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOI08fAjneqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Dropout(0.1)(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfIdjT6qnl5i",
        "colab_type": "text"
      },
      "source": [
        "Finally, we feed the output into a Sigmoid layer. The reason why sigmoid is used is because we are trying to achieve a binary classification(1,0) for each of the 6 labels, and the sigmoid function will squash the output between the bounds of 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux2cQ8fDnjR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Dense(6, activation=\"sigmoid\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OwJlo0Mn0v7",
        "colab_type": "text"
      },
      "source": [
        "We are almost done! All is left is to define the inputs, outputs and configure the learning process. We have set our model to optimize our loss function using Adam optimizer, define the loss function to be \"binary_crossentropy\" since we are tackling a binary classification. In case you are looking for the learning rate, the default is set at 0.001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OD5xeQLno4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXb6M8zPn6rC",
        "colab_type": "text"
      },
      "source": [
        "It's finally time to put our model to the test. We'll feed in a list of 32 padded, indexed sentence for each batch and split 10% of the data as a validation set. This validation set will be used to assess whether the model has overfitted, for each batch. The model will also run for 2 epochs. These are some of the tunable parameters that you can experiment with, to see if you can push the accurate to the next level without crashing your machine(hence the batch size)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufYWC70Gn4Ai",
        "colab_type": "code",
        "outputId": "48e1d1e5-f90f-4cce-fb2a-ca208e44c1f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 2\n",
        "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/2\n",
            "143613/143613 [==============================] - 537s 4ms/step - loss: 0.0678 - accuracy: 0.9779 - val_loss: 0.0498 - val_accuracy: 0.9815\n",
            "Epoch 2/2\n",
            "143613/143613 [==============================] - 532s 4ms/step - loss: 0.0455 - accuracy: 0.9829 - val_loss: 0.0468 - val_accuracy: 0.9826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f2d62f34b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJothKGPtLtf",
        "colab_type": "text"
      },
      "source": [
        "the accuracy is pretty decent, furthermore we can adjust the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUbtK7rEn_CN",
        "colab_type": "code",
        "outputId": "23b12646-5937-4a8a-882b-d0e95633e36a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 200, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "lstm_layer (LSTM)            (None, 200, 60)           45360     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                3050      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 2,608,716\n",
            "Trainable params: 2,608,716\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-QQbbkmtkBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_lstm=model.predict(X_te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AG6wVWkvQPz",
        "colab_type": "code",
        "outputId": "4ed4abb8-0c30-4fb5-932c-276c18b8355e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "pred_lstm"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9672180e-01, 4.3262917e-01, 9.5578039e-01, 1.3816160e-01,\n",
              "        9.0893239e-01, 2.6962963e-01],\n",
              "       [1.4660954e-03, 2.3065004e-06, 8.0007696e-05, 3.8518683e-06,\n",
              "        1.2442470e-04, 2.7977556e-05],\n",
              "       [2.7725697e-03, 1.0901669e-05, 1.9001961e-04, 1.5692594e-05,\n",
              "        3.3110380e-04, 8.2377388e-05],\n",
              "       ...,\n",
              "       [1.1059642e-03, 8.2784788e-07, 4.9463000e-05, 1.6336829e-06,\n",
              "        6.7029723e-05, 1.4768184e-05],\n",
              "       [2.7576089e-03, 1.5146145e-06, 9.1697962e-05, 4.3720834e-06,\n",
              "        1.3509393e-04, 3.1187596e-05],\n",
              "       [9.6741378e-01, 3.8724333e-02, 7.8003013e-01, 1.0074019e-02,\n",
              "        6.4236188e-01, 3.9511949e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYvxf33Av_b7",
        "colab_type": "text"
      },
      "source": [
        "Creating the submission file for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAwA1AyNv0eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submid2 = pd.DataFrame({'id': subm[\"id\"]})\n",
        "submission2 = pd.concat([submid2, pd.DataFrame(preds, columns = labels)], axis=1)\n",
        "submission2.to_csv('submission2.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTQ8zkoYwHPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFtD8mv1wQFA",
        "colab_type": "text"
      },
      "source": [
        "# Applying the Ensemble "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1wYYtKzwg6I",
        "colab_type": "text"
      },
      "source": [
        "In theory, an ensemble works best when the individual models are as different as possible. Therefore, we should see that even a simple average of these two models gets a good result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLDmqks3wfCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_lstm = pd.read_csv('submission2.csv')\n",
        "res_nbsvm = pd.read_csv('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hAPQzu3wsLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_final = res_lstm.copy()\n",
        "res_final[labels] = (res_nbsvm[labels] + res_lstm[labels]) / 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjayXxWNxZeN",
        "colab_type": "text"
      },
      "source": [
        "Now we create the final result csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC3QfWQrw-0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_final.to_csv('submission_final.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BExyER7FxfAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('submission_final.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lScmn89WrnQa",
        "colab_type": "text"
      },
      "source": [
        "**The stated method gives an accuracy of 0.9778 on Kaggle.**"
      ]
    }
  ]
}